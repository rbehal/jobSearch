{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jobGrab - Project to compile job search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import regex as re\n",
    "import json\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import xlsxwriter as xw\n",
    "# from bitly_api import bitly_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNL(string): # Helper function to remove new line\n",
    "    removeChars = [\"\\n\", \"\\r\"]\n",
    "    for i in range(0, 5): \n",
    "        for char in removeChars:\n",
    "            string = re.sub(char + '$', '', string)\n",
    "            string = re.sub('^' + char, '', string)\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSoup(URL): # Create HTML parsed BS object from URL\n",
    "    source = urllib \\\n",
    "        .request \\\n",
    "        .urlopen(URL) \\\n",
    "        .read()\n",
    "    return bs.BeautifulSoup(source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeJobsToIgnore(): # Creates array of jobs to ignore\n",
    "    file = open(\"src/jobsToIgnore.txt\", \"r\")\n",
    "    jobsToIgnoreRaw = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    jobsToIgnore = []\n",
    "    \n",
    "    for job in jobsToIgnoreRaw:\n",
    "        jobsToIgnore.append(job[1:(len(job) - 2)])\n",
    "    \n",
    "    return jobsToIgnore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkJobsToIgnore(job, jobsToIgnore):\n",
    "    if ((job.title + job.company) in jobsToIgnore):\n",
    "        return False\n",
    "    else:\n",
    "        return True    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeed Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndeedJob:\n",
    "    def __init__(self, ID, soup):\n",
    "        self.id = ID\n",
    "        self.posting = soup.find(attrs={\"data-jk\": ID})\n",
    "        self.platform = \"Indeed\"\n",
    "        \n",
    "        self.setTitle()\n",
    "        self.setCompany()\n",
    "        \n",
    "        if not checkJobsToIgnore(self):\n",
    "            self.valid = False\n",
    "            return\n",
    "        else:\n",
    "            self.valid = True\n",
    "            \n",
    "        self.setDatePosted()\n",
    "        self.setLocation()\n",
    "        self.setDetailedSoup()\n",
    "        self.setDescription()\n",
    "        self.setApply()\n",
    "       \n",
    "    \n",
    "    def setTitle(self):\n",
    "        self.title = self.posting.find(\"h2\", class_ = \"title\").text\n",
    "        self.title = removeNL(self.title)\n",
    "    \n",
    "        \n",
    "    def setDatePosted(self):\n",
    "        self.datePosted = self.posting.find(\"span\", class_ = \"date\").text  \n",
    "        today = date.today()\n",
    "        \n",
    "        if (self.datePosted == \"Today\" or self.datePosted == \"Just posted\"):\n",
    "            self.datePosted = today.strftime(\"%m/%d/%y\")\n",
    "        elif (self.datePosted[0:2].isdigit()): # Checks if more than 9 days ago\n",
    "            datetimePosted = today - timedelta(days=int(self.datePosted[0:2])) # Gets datetime object\n",
    "            self.datePosted = datetimePosted.strftime(\"%m/%d/%y\")\n",
    "        else:\n",
    "            datetimePosted = today - timedelta(days=int(self.datePosted[0])) # Gets datetime object\n",
    "            self.datePosted = datetimePosted.strftime(\"%m/%d/%y\")\n",
    "          \n",
    "        \n",
    "    def setLocation(self):\n",
    "        def checkLocation(class_):\n",
    "            return class_ is not None and \"location\" in class_\n",
    "        self.location = self.posting.find(class_ = checkLocation).text \n",
    "        \n",
    "        \n",
    "    def setCompany(self):\n",
    "        self.company = self.posting.find(\"span\", class_ = \"company\").text\n",
    "        self.company = removeNL(self.company)\n",
    "        \n",
    "        \n",
    "    def setDetailedSoup(self):# Soup for the separate page for viewing job description\n",
    "        self.detailsURL = \"https://ca.indeed.com/viewjob\" + \"?jk=\" + self.id\n",
    "        self.detailedSoup = createSoup(self.detailsURL)\n",
    "        \n",
    "        \n",
    "    def setDescription(self):   \n",
    "        descriptionTextDiv = self.detailedSoup.find(\"div\", {\"id\" : \"jobDescriptionText\"})\n",
    "        self.description = \"\"\n",
    "        for element in descriptionTextDiv.findAll(['p', 'li']): # Creates description adding newlines between paragraphs\n",
    "            if (element.name is 'p'):\n",
    "                self.description += element.text + 2*chr(10) # 10 is new line character\n",
    "            else:\n",
    "                self.description += element.text + chr(10)\n",
    "            \n",
    "            \n",
    "    def setApply(self):\n",
    "        applyLinkDiv = self.detailedSoup.find(\"div\", {\"id\" : \"viewJobButtonLinkContainer\"})\n",
    "        \n",
    "        if applyLinkDiv is not None:\n",
    "            self.applyLink = applyLinkDiv.find(\"div\", class_ = \"icl-u-lg-hide\").find('a').get('href')\n",
    "        else:\n",
    "            self.applyLink = self.detailsURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndeedJobs(searchTerm):\n",
    "    filteredTerm = \"\"\n",
    "    for letter in searchTerm: # Replacing spaces with +s for indeed query\n",
    "        if (letter != \" \"):\n",
    "            filteredTerm += letter\n",
    "        else:\n",
    "            filteredTerm += \"+\"\n",
    "    \n",
    "    soup = createSoup(\"https://ca.indeed.com/jobs?q=\" + filteredTerm + \"&l=Canada&sort=date\")\n",
    "        \n",
    "    for script in soup.find_all(\"script\", {\"src\":False}):\n",
    "        if (\"jobKeysWithInfo['\" in script.text): # This is where jobIDs are stored\n",
    "            jobIDsHTML = script.text\n",
    "            \n",
    "    # Create array of jobs\n",
    "    jobIDRawPattern = re.compile(r\"^(.+?)jobKeysWithInfo\\['(.+?)'\\](.+?)$\", re.MULTILINE | re.DOTALL)\n",
    "    jobIDsRaw = re.findall(jobIDRawPattern, jobIDsHTML)\n",
    "    jobIDPattern = re.compile(r\"^[A-Fa-f0-9]{16}$\")\n",
    "    jobs = []\n",
    "    \n",
    "    for row in jobIDsRaw:\n",
    "        for entry in row:\n",
    "            if re.match(jobIDPattern, entry):                \n",
    "                # Creating job\n",
    "                job = IndeedJob(entry, soup)\n",
    "                if (job.valid):\n",
    "                    jobs.append(job)    \n",
    "\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monster Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:75: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:75: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-64-9e5582bda000>:75: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if (element.name is 'p'):\n"
     ]
    }
   ],
   "source": [
    "class MonsterJob:\n",
    "    def __init__(self, ID, posting):\n",
    "        self.id = ID\n",
    "        self.posting = posting\n",
    "        self.platform = \"Monster\"\n",
    "        \n",
    "        self.setTitle()\n",
    "        self.setCompany()\n",
    "        \n",
    "#         if not checkJobsToIgnore(self):\n",
    "#             self.valid = False\n",
    "#             return\n",
    "#         else:\n",
    "#             self.valid = True\n",
    "            \n",
    "        self.setDatePosted()\n",
    "        self.setLocation()\n",
    "        self.setDetailedSoup()\n",
    "        self.setDescription()\n",
    "        self.setApply()\n",
    "        \n",
    "        \n",
    "    def setTitle(self):\n",
    "        self.titleSoup = self.posting.find(\"h2\", class_ = \"title\") \n",
    "        self.title = removeNL(self.titleSoup.text)\n",
    "        \n",
    "        \n",
    "    def setDatePosted(self):\n",
    "        self.datePosted = self.posting.find(\"time\").text  \n",
    "        today = date.today()\n",
    "\n",
    "        if (self.datePosted[0:2].isdigit()): # Checks if more than 9 days ago\n",
    "            datetimePosted = today - timedelta(days=int(self.datePosted[0:2])) # Gets datetime object\n",
    "            self.datePosted = datetimePosted.strftime(\"%m/%d/%y\")\n",
    "        elif (self.datePosted[0].isdigit()):\n",
    "            datetimePosted = today - timedelta(days=int(self.datePosted[0])) # Gets datetime object\n",
    "            self.datePosted = datetimePosted.strftime(\"%m/%d/%y\")\n",
    "        else:\n",
    "            self.datePosted = today.strftime(\"%m/%d/%y\")          \n",
    "        \n",
    "        \n",
    "    def setLocation(self):\n",
    "        locationClass = self.posting.find(\"div\", class_ = \"location\")\n",
    "        self.location = removeNL(locationClass.find(\"span\", class_ = \"name\").text)\n",
    "        self.location = self.location.title() # Convers to proper case\n",
    "        \n",
    "        \n",
    "    def setCompany(self):\n",
    "        locationClass = self.posting.find(\"div\", class_ = \"company\")\n",
    "        self.company = removeNL(locationClass.find(\"span\", class_ = \"name\").text)\n",
    "    \n",
    "    \n",
    "    def setDetailedSoup(self):# Soup for the separate page for viewing job description\n",
    "        self.detailsURL = self.titleSoup.find(\"a\").get(\"href\")\n",
    "        try: # Causes error if non ASCII characters are in the link\n",
    "            self.detailedSoup = createSoup(self.detailsURL)\n",
    "        except:\n",
    "            self.detailedSoup = None\n",
    "        \n",
    "        \n",
    "    def setDescription(self):   \n",
    "        if (self.detailedSoup is None):\n",
    "            self.description = None\n",
    "            return;        \n",
    "        \n",
    "        # Creates description adding newlines between paragraphs\n",
    "        descriptionTextDiv = self.detailedSoup.findAll(['p', 'li'])\n",
    "        \n",
    "        if (descriptionTextDiv is not None):\n",
    "            self.description = \"\"\n",
    "        else:\n",
    "            self.description = None\n",
    "\n",
    "        for element in descriptionTextDiv[14:(len(descriptionTextDiv) - 1)]: # Slices to only get necessary text\n",
    "            if (element.name is 'p'):\n",
    "                self.description += element.text + 2*chr(10) # 10 is new line character\n",
    "            else:\n",
    "                self.description += element.text + chr(10)           \n",
    "            \n",
    "    def setApply(self):        \n",
    "        if (self.detailedSoup is None or (\"applyOnlineUrl\" in str(self.detailedSoup)) is False):\n",
    "            self.applyLink = None\n",
    "            return\n",
    "        else:\n",
    "            applyLinkHTML = str(self.detailedSoup)\n",
    "    \n",
    "        applyLinkRawPattern = re.compile(r\"^(.+?)applyOnlineUrl\\\":\\\"(.+?)\\\",\\\"applyType(.+?)$\", re.MULTILINE | re.DOTALL) # Regex for where the URL is stored\n",
    "\n",
    "        applyLinkRaw = re.search(applyLinkRawPattern, applyLinkHTML) # Raw pattern\n",
    "        applyLinkRaw = applyLinkRaw.group(2).replace(\"u002F\", \"\") # Removes u002F characters\n",
    "\n",
    "        # If there is an ad link, remove the ad part \n",
    "        applyLinkAdPattern = re.compile(r\"^https:(.+?)ad.doubleclick.net(.+?)\\?(.+?)$\", re.MULTILINE | re.DOTALL)\n",
    "        applyLinkAdRaw = re.search(applyLinkAdPattern, applyLinkRaw)\n",
    "\n",
    "        # Set the final apply links\n",
    "        if applyLinkAdRaw is None:\n",
    "            self.applyLink = applyLinkRaw\n",
    "        else:\n",
    "            self.applyLink = applyLinkAdRaw.group(3)\n",
    "            \n",
    "        self.applyLink = self.applyLink.replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if len(self.applyLink) >= 250:\n",
    "            self.applyLink = shortenLink(self.applyLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonsterJobs(searchTerm):\n",
    "    filteredTerm = \"\"\n",
    "    for letter in searchTerm: # Replacing spaces with +s for indeed query\n",
    "        if (letter != \" \"):\n",
    "            filteredTerm += letter\n",
    "        else:\n",
    "            filteredTerm += \"-\"\n",
    "    \n",
    "    soup = createSoup(\"https://www.monster.ca/jobs/search/?q=\" + filteredTerm + \"&where=Canada\")\n",
    "    \n",
    "    # Creating jobs array\n",
    "    jobs = []\n",
    "    for section in soup.find_all(\"section\"):\n",
    "        jobID = section.get(\"data-jobid\")\n",
    "        if jobID is not None:\n",
    "            job = MonsterJob(jobID, section)\n",
    "#             if (job.valid):\n",
    "            jobs.append(job)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedInJob:\n",
    "    def __init__(self, ID, posting):\n",
    "        self.id = ID\n",
    "        self.posting = posting\n",
    "        self.platform = \"LinkedIn\"\n",
    "        \n",
    "        self.setTitle()\n",
    "        self.setCompany()\n",
    "        \n",
    "        if not checkJobsToIgnore(self):\n",
    "            self.valid = False\n",
    "            return\n",
    "        else:\n",
    "            self.valid = True\n",
    "            \n",
    "        self.setDetailedSoup()\n",
    "        self.setDatePosted()\n",
    "        self.setLocation()\n",
    "        self.setDescription()\n",
    "        self.setApply()\n",
    "        \n",
    "        \n",
    "    def setTitle(self):\n",
    "        self.title = self.posting.find(\"span\", class_ = \"screen-reader-text\").text        \n",
    "        \n",
    "        \n",
    "    def setDatePosted(self):\n",
    "        def checkDateClass(class_):\n",
    "            return class_ is not None and \"listdate\" in class_ \n",
    "        \n",
    "        self.datePosted = self.posting.find(\"time\", class_ = checkDateClass).text        \n",
    "        today = date.today()\n",
    "        \n",
    "        if (\"hour\" in self.datePosted):\n",
    "            self.datePosted = today.strftime(\"%m/%d/%y\")\n",
    "        elif (self.datePosted[0:2].isdigit()): # Checks if more than 9 days ago\n",
    "            datetimePosted = today - timedelta(days=int(self.datePosted[0:2])) # Gets datetime object\n",
    "            self.datePosted = datetimePosted.strftime(\"%m/%d/%y\")\n",
    "        else:\n",
    "            datetimePosted = today - timedelta(days=int(self.datePosted[0])) # Gets datetime object\n",
    "            self.datePosted = datetimePosted.strftime(\"%m/%d/%y\")\n",
    "        \n",
    "        \n",
    "    def setLocation(self):\n",
    "        self.location = self.posting.find(\"span\", class_ = \"job-result-card__location\").text\n",
    "        \n",
    "        \n",
    "    def setCompany(self):\n",
    "        def checkCompanyClass(class_):\n",
    "            return class_ is not None and \"result-card__subtitle\" in class_ \n",
    "        \n",
    "        companyDiv = self.posting.find(\"h4\", checkCompanyClass)\n",
    "        if (companyDiv is not None):\n",
    "            self.company = companyDiv.text\n",
    "        else:\n",
    "            self.company = None\n",
    "    \n",
    "    \n",
    "    def setDetailedSoup(self):# Soup for the separate page for viewing job description\n",
    "        self.detailsURL = self.posting.find(\"a\", class_ = \"result-card__full-card-link\").get(\"href\")\n",
    "        self.detailedSoup = createSoup(self.detailsURL)\n",
    "       \n",
    "        \n",
    "    def setDescription(self):  \n",
    "        descriptionTextDiv = self.detailedSoup.find(\"section\", class_ = \"description\").findAll(['p', 'li'])\n",
    "        \n",
    "        if (descriptionTextDiv is not None):\n",
    "            self.description = \"\"\n",
    "            for element in descriptionTextDiv:\n",
    "                if (element.name is 'p'):\n",
    "                    self.description += element.text + 2*chr(10) # 10 is new line character\n",
    "                else:\n",
    "                    self.description += element.text + chr(10)   \n",
    "        else:\n",
    "            self.description = None\n",
    "             \n",
    "        \n",
    "    def setApply(self):\n",
    "        applyDiv = self.detailedSoup.find(\"a\", class_ = \"apply-button apply-button--link\")\n",
    "        if (applyDiv is not None):\n",
    "            self.applyLink = shortenLink(applyDiv.get(\"href\")) # Will enact when in prduction to prevent wasted API calls\n",
    "            # self.applyLink = applyDiv.get(\"href\")\n",
    "        else:\n",
    "            self.applyLink = self.detailsURL\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinkedInJobs(searchTerm):\n",
    "    filteredTerm = \"\"\n",
    "    for letter in searchTerm: # Replacing spaces with %20s for indeed query\n",
    "        if (letter != \" \"):\n",
    "            filteredTerm += letter\n",
    "        else:\n",
    "            filteredTerm += \"%20\"\n",
    "\n",
    "    URL = \"https://www.linkedin.com/jobs/search/?geoId=101174742&keywords=\" + filteredTerm + \"&location=Canada&sortBy=DD&f_TP=1%2C2&redirect=false&position=1&pageNum=0\"\n",
    "    \n",
    "    try: # Perhaps handle differently later\n",
    "        soup = createSoup(URL)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    def postingCheck(entityUrn):\n",
    "        return entityUrn is not None and \"jobPosting\" in entityUrn\n",
    "    jobPostings = soup.findAll(\"li\", {\"data-entity-urn\" : postingCheck}) #jobPostings follow this\n",
    "    \n",
    "    # Creating jobs array\n",
    "    jobs = []\n",
    "    for posting in jobPostings:\n",
    "        jobID = posting.get(\"data-id\")\n",
    "        if jobID is not None:\n",
    "            job = LinkedInJob(jobID, posting)\n",
    "            if (job.valid):\n",
    "                jobs.append(job)\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting List of Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchTerm = \"Engineering Intern\"\n",
    "indeedJobs =  getIndeedJobs(searchTerm)\n",
    "monsterJobs = getMonsterJobs(searchTerm)\n",
    "linkedInJobs = getLinkedInJobs(searchTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = indeedJobs + monsterJobs + linkedInJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSimilarJobs(jobs):  # Takes in a jobs array and returns the array with duplicate jobs removed\n",
    "    def cleanString(description): # Helper function - Normalizes text\n",
    "        description = ''.join([word for word in description if word not in string.punctuation])\n",
    "        description = description.lower()\n",
    "\n",
    "        temp = []\n",
    "        for word in description.split():\n",
    "            if word not in stopwords:\n",
    "                temp.append(word)\n",
    "\n",
    "        description = ' '.join(temp)\n",
    "\n",
    "        return description\n",
    "    \n",
    "    def cosineSimVectors(vec1, vec2): # Helper function - Retrieve similarity (0-1)\n",
    "        vec1 = vec1.reshape(1, -1)\n",
    "        vec2 = vec2.reshape(1, -1)\n",
    "\n",
    "        return cosine_similarity(vec1, vec2)[0][0]\n",
    "    \n",
    "    \n",
    "    jobDescriptions = [job.description for job in jobs]\n",
    "    cleanDescriptions = list(map(cleanString, jobDescriptions))  \n",
    "    \n",
    "    vectorizer = CountVectorizer().fit_transform(cleanDescriptions)\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    indicesToRemove = []\n",
    "    for i in range(0, len(vectors)):\n",
    "        for j in range(i + 1, len(vectors)):\n",
    "            if (cosineSimVectors(vectors[i], vectors[j]) > 0.9):\n",
    "                indicesToRemove.append(j)\n",
    "\n",
    "    indicesToRemove = list(set(indicesToRemove))\n",
    "    \n",
    "    jobsToRemove = [] # Must do this in two loops because dynamically removing changes indexing\n",
    "    for index in indicesToRemove:\n",
    "        jobsToRemove.append(jobs[index])\n",
    "    for job in jobsToRemove:\n",
    "        jobs.remove(job)\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = removeSimilarJobs(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for job in jobs:\n",
    "    row = []\n",
    "    \n",
    "    row.append(job.title)\n",
    "    row.append(job.company)\n",
    "    row.append(job.datePosted)\n",
    "    row.append(job.location)\n",
    "    row.append(job.description)\n",
    "    row.append(job.applyLink)\n",
    "    row.append(job.platform)\n",
    "    \n",
    "    data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fileSavePath = 'C:/Users/Rahul Behal/Desktop/jobs.xlsm'\n",
    "\n",
    "workbook = xw.Workbook(fileSavePath)\n",
    "\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "tableLength = str(len(jobs) + 1) # Amount of objects in the table + 1 for header\n",
    "tableRange = 'A1:G' + tableLength \n",
    "tableDataRange = 'A2:G' + tableLength\n",
    "\n",
    "\n",
    "worksheet.add_table(tableRange, {'data': data,\n",
    "                                 'columns': [{'header' : 'Position Title'},\n",
    "                                             {'header' : 'Company'},\n",
    "                                             {'header' : 'Date Posted'},\n",
    "                                             {'header' : 'Location'},\n",
    "                                             {'header' : 'Description'},\n",
    "                                             {'header' : 'Apply Link'},\n",
    "                                             {'header' : 'Platform'}],\n",
    "                                 'style' : \"Table Style Light 8\"\n",
    "                                 }) # Each job has 7 (G) attributes\n",
    "\n",
    "\n",
    "# Conditional formatting based on platform\n",
    "worksheet.conditional_format(tableDataRange, {'type':     'formula',\n",
    "                                              'criteria': '=$G2=\"LinkedIn\"',\n",
    "                                              'format':   workbook.add_format({'bg_color' : '#FFB3B3'})})\n",
    "worksheet.conditional_format(tableDataRange, {'type':     'formula',\n",
    "                                              'criteria': '=$G2=\"Indeed\"',\n",
    "                                              'format':   workbook.add_format({'bg_color' : '#B3FFCC'})})\n",
    "worksheet.conditional_format(tableDataRange, {'type':     'formula',\n",
    "                                              'criteria': '=$G2=\"Monster\"',\n",
    "                                              'format':   workbook.add_format({'bg_color' : '#CC80FF'})})\n",
    "\n",
    "\n",
    "# Column Formatting\n",
    "cFormat = workbook.add_format({'align' : 'right', 'num_format' : 'mm/dd/yy'})# Column C (Date)\n",
    "eFormat = workbook.add_format({'text_wrap' : True, 'valign' : 'top'})# Column E (Description)\n",
    "\n",
    "\n",
    "# Adjusting column widths\n",
    "worksheet.set_column(0, 0, 50)\n",
    "worksheet.set_column(1, 1, 30)\n",
    "worksheet.set_column(2, 2, 12, cFormat)\n",
    "worksheet.set_column(3, 3, 15)\n",
    "worksheet.set_column(4, 4, 70, eFormat)\n",
    "worksheet.set_column(5, 5, 11)\n",
    "worksheet.set_column(6, 6, 10)\n",
    "\n",
    "# Adding VBA macro button for closing\n",
    "workbook.add_vba_project('./vbaProject.bin') \n",
    "\n",
    "worksheet.insert_button('E'+str(int(tableLength) + 2), {'macro':   'addJobsToIgnore.addJobsToIgnore',\n",
    "                                                        'caption': 'Done',\n",
    "                                                        'width':   200,\n",
    "                                                        'height':  100})\n",
    "\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
